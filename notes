language model
models a sequence of words (tokens) and it knows how
some words follow eachother in english. From the AI 
perspective when we give it a text sequence it
completes that sequence

activate environment
1. Make sure im in C:\Users\davie\VSCode_projects\Mini GPT
2. In terminal venv\Scripts\activate

So we define a sequence of characters first so the AI knows some context
then we pass it a chunk of a dataset (in this case a paragraph of
shakespeare).
And basing on what it already knows the AI can tell the most likely next 
letter in the word "char" is "g" and then "e" so it completes the word
"charge".

We are going to train the transformer on Shakespeare data so we can 
generate fake infinite shakespeare, generating character by character, 
knowing what the next most likely character is (basing on what it 
learned from shakespeare)

Tensor (programming): a multidimensional array, many vectors and 
matrixes. For example an array of numbers arranged on a grid with 
multiple axis

We feed the ai a tensor with various numbers, each number represents a 
chunk of the text. The transformer (GPT) processes many chunks at the 
same time and predicts integers (characters) for every position we pass 
to it

Feeding everything into a neural network
